{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNz-yh2HFz_G"
      },
      "source": [
        "論文<br>\n",
        "https://arxiv.org/abs/2111.15666<br>\n",
        "<br>\n",
        "GitHub<br>\n",
        "https://github.com/yuval-alaluf/hyperstyle<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/hyperstyle_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIyC-kLNGZiQ"
      },
      "source": [
        "# ランタイムの設定\n",
        "「ランタイム」→「ランタイムのタイプを変更」→「ハードウェアアクセラレータ」をGPUに変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amOVuN1yGsZI"
      },
      "source": [
        "# 実行方法\n",
        "「ランタイム」→「すべてのセルを実行」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKo4CcvmGwJ-"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tr1tqeCq6vw",
        "outputId": "e6716d37-1cb6-423c-d198-dbb901d96d68"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEdxoG5jrCc5"
      },
      "source": [
        "## GithubからCode clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBphrlXDrHWc",
        "outputId": "3a4036f5-1736-4c4c-a0f5-1a65d57900ef"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "# for hyperstyle\n",
        "!git clone https://github.com/yuval-alaluf/hyperstyle.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baPoVAl_q8wu"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt4EMaozq9pj",
        "outputId": "c74967cb-a5f3-490c-dea6-5b6e28548e3d"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "\n",
        "!pip install --upgrade gdown\n",
        "!pip install moviepy\n",
        "\n",
        "# install ninja\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQI43xjHsugU"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR0M9Wg8sv8q",
        "outputId": "8819478c-8b77-44dd-b992-aa57cd1574df"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "\n",
        "import time\n",
        "import sys\n",
        "import pprint\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import gdown\n",
        "import glob\n",
        "\n",
        "import imageio\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from moviepy.video.fx.resize import resize\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "from notebooks.notebook_utils import Downloader, HYPERSTYLE_PATHS, W_ENCODERS_PATHS, run_alignment\n",
        "from utils.common import tensor2im\n",
        "from utils.inference_utils import run_inversion\n",
        "from utils.domain_adaptation_utils import run_domain_adaptation\n",
        "from utils.model_utils import load_model, load_generator\n",
        "\n",
        "SEED = 12\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK43dSaxaU3X"
      },
      "source": [
        "# 学習済みモデルのセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4GJMZLaaXJS",
        "outputId": "c0e4f3bb-d963-4089-80ea-401263ae983d"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "!mkdir pretrained_models\n",
        "\n",
        "hyper = \"./pretrained_models/hyperstyle_ffhq.pt\"\n",
        "w_encoder = \"./pretrained_models/faces_w_encoder.pt\"\n",
        "\n",
        "if not os.path.exists(hyper):\n",
        "  gdown.download('https://drive.google.com/uc?id='+'1C3dEIIH1y8w1-zQMCyx7rDF0ndswSXh4', hyper, quiet=False)\n",
        "if not os.path.exists(w_encoder):\n",
        "  gdown.download('https://drive.google.com/uc?id='+'1M-hsL3W_cJKs77xM1mwq2e9-J0_m7rHP', w_encoder, quiet=False)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "                                transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXpJifRVI5Zx"
      },
      "source": [
        "# テスト画像のセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7jURutCzrON",
        "outputId": "73e06605-2c52-40c8-f8e9-5a3662da016a"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "!mkdir input_imgs\n",
        "\n",
        "# root_dir = \"./notebooks/images/animations\"\n",
        "# image_paths = glob.glob(root_dir+\"/*.jpg\")\n",
        "\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/SAYA160312500I9A3721_TP_V4.jpg -O ./input_imgs/test_1.jpg\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/SAYA072160333_TP_V4.jpg -O ./input_imgs/test_2.jpg\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/saya0I9A4189072170014_TP_V4.jpg -O ./input_imgs/test_3.jpg\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/SAYA160312500I9A3721_TP_V4.jpg -O ./input_imgs/test_4.jpg\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/SAYA0I9A8598_TP_V4.jpg -O ./input_imgs/test_5.jpg\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/akanesaya0I9A3747_TP_V4.jpg -O ./input_imgs/test_6.jpg\n",
        "\n",
        "root_dir = \"./input_imgs\"\n",
        "image_paths = glob.glob(root_dir+\"/*.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF5ZUeUXJige"
      },
      "source": [
        "# モデルのロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-3QxYbyJlME",
        "outputId": "70b078a0-c1e7-42a5-9539-c8207ec5a810"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "\n",
        "net, opts = load_model(hyper, update_opts={\"w_encoder_checkpoint_path\": w_encoder})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXoLxHrDJ6c7"
      },
      "source": [
        "# Utility関数定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmVReGZ5J8on"
      },
      "outputs": [],
      "source": [
        "# image to mp4\n",
        "def generate_mp4(out_name, images, kwargs):\n",
        "  writer = imageio.get_writer(out_name + '.mp4', **kwargs)\n",
        "  for image in images:\n",
        "    writer.append_data(image)\n",
        "  writer.close()\n",
        "\n",
        "def get_latent_and_weight_deltas(inputs, net, opts):\n",
        "  opts.resize_outputs = False\n",
        "  opts.n_iters_per_batch = 5\n",
        "  with torch.no_grad():\n",
        "    _, latent, weights_deltas, _ = run_inversion(inputs.to(\"cuda\").float(), net, opts)\n",
        "  weights_deltas = [w[0] if w is not None else None for w in weights_deltas]\n",
        "  return latent, weights_deltas\n",
        "\n",
        "def get_result_from_vecs(vectors_a, vectors_b, weights_deltas_a, weights_deltas_b, alpha):\n",
        "  results = []\n",
        "  for i in range(len(vectors_a)):\n",
        "    with torch.no_grad():\n",
        "      cur_vec = vectors_b[i] * alpha + vectors_a[i] * (1 - alpha)\n",
        "      cur_weight_deltas = interpolate_weight_deltas(weights_deltas_a, weights_deltas_b, alpha)\n",
        "      res = net.decoder(\n",
        "          [cur_vec],\n",
        "          weights_deltas=cur_weight_deltas,\n",
        "          randomize_noise=False,\n",
        "          input_is_latent=True)[0]\n",
        "      results.append(res[0])\n",
        "  return results\n",
        "\n",
        "def interpolate_weight_deltas(weights_deltas_a, weights_deltas_b, alpha):\n",
        "  cur_weight_deltas = []\n",
        "  for weight_idx, w in enumerate(weights_deltas_a):\n",
        "    if w is not None:\n",
        "      delta = weights_deltas_b[weight_idx] * alpha + weights_deltas_a[weight_idx] * (1 - alpha)\n",
        "    else:\n",
        "      delta = None\n",
        "    cur_weight_deltas.append(delta)\n",
        "  return cur_weight_deltas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEWVh3yIMEaY"
      },
      "source": [
        "# face align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN1ps-R8MF-9",
        "outputId": "dfab00dd-e6a7-4a02-ad7c-9001779c8088"
      },
      "outputs": [],
      "source": [
        "%cd /content/hyperstyle\n",
        "\n",
        "aligned_image_paths = []\n",
        "for image_path in image_paths:\n",
        "  image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "  aligned_image = run_alignment(image_path)\n",
        "  aligned_path = os.path.join(root_dir, f'{image_name}_aligned.jpg')\n",
        "  # save the aligned image\n",
        "  aligned_image.save(aligned_path)\n",
        "  aligned_image_paths.append(aligned_path)\n",
        "  # use the save aligned images as our input image paths\n",
        "  image_paths = aligned_image_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ArLKDLNa2L"
      },
      "source": [
        "# invert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAAnR8qsNcRe"
      },
      "outputs": [],
      "source": [
        "in_images = []\n",
        "all_vecs = []\n",
        "all_weights_deltas = []\n",
        "\n",
        "resize_amount = (opts.output_size, opts.output_size)\n",
        "\n",
        "# Inference\n",
        "for image_path in image_paths:\n",
        "  original_image = Image.open(image_path)\n",
        "  original_image = original_image.convert(\"RGB\")\n",
        "  input_image = img_transforms(original_image)\n",
        "  # get the weight deltas for each image\n",
        "  result_vec, weights_deltas = get_latent_and_weight_deltas(input_image.unsqueeze(0), net, opts)\n",
        "  all_vecs.append([result_vec])\n",
        "  all_weights_deltas.append(weights_deltas)\n",
        "  in_images.append(original_image.resize(resize_amount))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKOcGaHNyYj"
      },
      "source": [
        "# Interpolate & Concat images for animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0s7uqHmNzr-",
        "outputId": "9780890b-5026-4d25-f2fb-f0ffd098df86"
      },
      "outputs": [],
      "source": [
        "n_transition = 25\n",
        "SIZE = opts.output_size\n",
        "\n",
        "images = []\n",
        "image_paths.append(image_paths[0])\n",
        "all_vecs.append(all_vecs[0])\n",
        "all_weights_deltas.append(all_weights_deltas[0])\n",
        "in_images.append(in_images[0])\n",
        "\n",
        "for i in range(1, len(image_paths)):\n",
        "  if i == 0:\n",
        "    alpha_vals = [0] * 10 + np.linspace(0, 1, n_transition).tolist() + [1] * 5\n",
        "  else:\n",
        "    alpha_vals = [0] * 5 + np.linspace(0, 1, n_transition).tolist() + [1] * 5\n",
        "  for alpha in tqdm(alpha_vals):\n",
        "    image_a = np.array(in_images[i - 1])\n",
        "    image_b = np.array(in_images[i])\n",
        "    image_joint = np.zeros_like(image_a)\n",
        "    up_to_row = int((SIZE - 1) * alpha)\n",
        "    if up_to_row > 0:\n",
        "      image_joint[:(up_to_row + 1), :, :] = image_b[((SIZE - 1) - up_to_row):, :, :]\n",
        "    if up_to_row < (SIZE - 1):\n",
        "      image_joint[up_to_row:, :, :] = image_a[:(SIZE - up_to_row), :, :]\n",
        "    result_image = get_result_from_vecs(\n",
        "        all_vecs[i - 1], all_vecs[i],\n",
        "        all_weights_deltas[i - 1], all_weights_deltas[i],alpha)[0]\n",
        "\n",
        "    output_im = tensor2im(result_image)\n",
        "    res = np.concatenate([image_joint, np.array(output_im)], axis=1)\n",
        "    images.append(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgMsije3O0RZ"
      },
      "source": [
        "# show result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "X-Mcg-tMOzsm",
        "outputId": "9de550b1-b61b-4d2f-ec40-90bbd8afedc9"
      },
      "outputs": [],
      "source": [
        "kwargs = {'fps': 15}\n",
        "save_path = \"./output\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "gif_path = os.path.join(save_path, \"face_gif\")\n",
        "generate_mp4(gif_path, images, kwargs)\n",
        "\n",
        "clip = VideoFileClip(gif_path+\".mp4\")\n",
        "clip = resize(clip, height=420)\n",
        "clip.ipython_display()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PIyC-kLNGZiQ",
        "amOVuN1yGsZI"
      ],
      "name": "hyperstyle_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "69158ccfe43d0b962045f592ede11796dd42f250837ab62152c8bc6cd100a15b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
