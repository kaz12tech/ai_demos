{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NENcrgDJv9q"
      },
      "source": [
        "論文  \n",
        "https://arxiv.org/abs/2207.13691<br>\n",
        "<br>\n",
        "GitHub  \n",
        "https://github.com/zubair-irshad/shapo<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/shapo_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHqYjlJ4Jv9u"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7jySK7RJv9v"
      },
      "source": [
        "## GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PcII5fLdHnJ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaAzHlBvJv9y"
      },
      "source": [
        "## GitHubからコード取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-Y5auuvnnnT"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/zubair-irshad/shapo.git\n",
        "\n",
        "# Commits on Nov 8, 2022\n",
        "%cd /content/shapo\n",
        "!git checkout 9269bf4ba74bc86022449ebc598cd79b9c2630c4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tp-fduPJv9z"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LScsvO3UppqT"
      },
      "outputs": [],
      "source": [
        "%cd /content/shapo\n",
        "\n",
        "!pip install -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!wget https://www.dropbox.com/s/cvqyhr67zpxyq36/test_subset.tar.xz?dl=1 -O test_subset.tar.xz\n",
        "!tar -xvf test_subset.tar.xz\n",
        "\n",
        "!wget https://www.dropbox.com/s/929kz7zuxw8jajy/sdf_rgb_pretrained.tar.xz?dl=1 -O sdf_rgb_pretrained.tar.xz\n",
        "! tar -xvf sdf_rgb_pretrained.tar.xz\n",
        "!wget https://www.dropbox.com/s/nrsl67ir6fml9ro/ckpts.tar.xz?dl=1 -O ckpts.tar.xz\n",
        "!tar -xvf ckpts.tar.xz\n",
        "\n",
        "!mkdir test_data\n",
        "!mv test_subset/* test_data\n",
        "!mv sdf_rgb_pretrained test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIWoFf9MJv91"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2lxptJeo6kr"
      },
      "outputs": [],
      "source": [
        "%cd /content/shapo\n",
        "\n",
        "import argparse\n",
        "import pathlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import pytorch_lightning as pl\n",
        "import _pickle as cPickle\n",
        "import os, sys\n",
        "\n",
        "from simnet.lib.net import common\n",
        "from simnet.lib import camera\n",
        "from simnet.lib.net.panoptic_trainer import PanopticModel\n",
        "from utils.nocs_utils import load_img_NOCS, create_input_norm\n",
        "from utils.viz_utils import depth2inv, viz_inv_depth\n",
        "from utils.transform_utils import get_gt_pointclouds, transform_coordinates_3d, calculate_2d_projections\n",
        "from utils.transform_utils import project, get_pc_absposes, transform_pcd_to_canonical\n",
        "from utils.viz_utils import save_projected_points, draw_bboxes, line_set_mesh, display_gird, draw_geometries, show_projected_points\n",
        "from sdf_latent_codes.get_surface_pointcloud import get_surface_pointclouds_octgrid_viz, get_surface_pointclouds\n",
        "from sdf_latent_codes.get_rgb import get_rgbnet, get_rgb_from_rgbnet\n",
        "from sdf_latent_codes.get_surface_pointcloud import get_sdfnet\n",
        "from sdf_latent_codes.get_rgb import get_rgbnet\n",
        "from utils.transform_utils import get_abs_pose_vector_from_matrix, get_abs_pose_from_vector\n",
        "from utils.nocs_utils import get_masks_out, get_aligned_masks_segout, get_masked_textured_pointclouds\n",
        "from opt.optimization_all import Optimizer\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using device is\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習済みモデルのロード"
      ],
      "metadata": {
        "id": "WCt6DZV6eqTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "# load config\n",
        "sys.argv = ['', '@shapo/configs/net_config.txt']\n",
        "parser = argparse.ArgumentParser(fromfile_prefix_chars='@')\n",
        "common.add_train_args(parser)\n",
        "app_group = parser.add_argument_group('app')\n",
        "app_group.add_argument('--app_output', default='inference', type=str)\n",
        "app_group.add_argument('--result_name', default='shapo_inference', type=str)\n",
        "app_group.add_argument('--data_dir', default='shapo/test_data', type=str)\n",
        "\n",
        "# load model\n",
        "hparams = parser.parse_args()\n",
        "min_confidence = 0.50\n",
        "hparams.checkpoint = 'shapo/ckpts/shapo_real.ckpt'\n",
        "model = PanopticModel(hparams, 0, None, None)\n",
        "model.eval()\n",
        "if device == \"cuda\":\n",
        "    model.cuda()\n",
        "\n",
        "# set dataset \n",
        "data_path = open(os.path.join(hparams.data_dir, 'Real', 'test_list_subset.txt')).read().splitlines()\n",
        "_CAMERA = camera.NOCS_Real()\n",
        "sdf_pretrained_dir = os.path.join(hparams.data_dir, 'sdf_rgb_pretrained')\n",
        "rgb_model_dir = os.path.join(hparams.data_dir, 'sdf_rgb_pretrained', 'rgb_net_weights')"
      ],
      "metadata": {
        "id": "elpSqFlwer-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single shot Inference"
      ],
      "metadata": {
        "id": "NwkhgIxAgJs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#num from 0 to 3 (small subset of data)\n",
        "num = 1\n",
        "img_full_path = os.path.join(hparams.data_dir, 'Real', data_path[num])\n",
        "img_vis = cv2.imread(img_full_path + '_color.png')\n",
        "\n",
        "left_linear, depth, actual_depth = load_img_NOCS(img_full_path + '_color.png' , img_full_path + '_depth.png')\n",
        "input = create_input_norm(left_linear, depth)[None, :, :, :]\n",
        "    \n",
        "input = input.to(torch.device(device))\n",
        "\n",
        "with torch.no_grad():\n",
        "    seg_output, _, _ , pose_output = model.forward(input)\n",
        "    _, _, _ , pose_output = model.forward(input)\n",
        "    shape_emb_outputs, appearance_emb_outputs, abs_pose_outputs, peak_output, scores_out, output_indices = pose_output.compute_shape_pose_and_appearance(min_confidence,is_target = False)"
      ],
      "metadata": {
        "id": "1Kd1WsnkfiDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_gird(img_vis, depth, peak_output)"
      ],
      "metadata": {
        "id": "rJbAZUyHfnKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode shape with predicted textures from shape and appearance embeddings"
      ],
      "metadata": {
        "id": "WLA14cZwg5ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotated_pcds = []\n",
        "points_2d = []\n",
        "box_obb = []\n",
        "axes = [] \n",
        "lod = 7 # Choose from LOD 3-7 here, going higher means more memory and finer details\n",
        "\n",
        "# Here we visualize the output of our network\n",
        "for j in range(len(shape_emb_outputs)):\n",
        "    shape_emb = shape_emb_outputs[j]\n",
        "    # appearance_emb = appearance_emb_putputs[j]\n",
        "    appearance_emb = appearance_emb_outputs[j]\n",
        "    is_oct_grid = True\n",
        "    if is_oct_grid:\n",
        "        # pcd_dsdf_actual = get_surface_pointclouds_octgrid_sparse(shape_emb, sdf_latent_code_dir = sdf_pretrained_dir, lods=[2,3,4,5,6])\n",
        "        pcd_dsdf, nrm_dsdf = get_surface_pointclouds_octgrid_viz(shape_emb, lod=lod, sdf_latent_code_dir=sdf_pretrained_dir)\n",
        "    else:\n",
        "        pcd_dsdf = get_surface_pointclouds(shape_emb)\n",
        "    rgbnet = get_rgbnet(rgb_model_dir)\n",
        "    pred_rgb = get_rgb_from_rgbnet(shape_emb, pcd_dsdf, appearance_emb, rgbnet)\n",
        "    rotated_pc, rotated_box, _ = get_pc_absposes(abs_pose_outputs[j], pcd_dsdf)\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(np.copy(rotated_pc))\n",
        "    pcd.colors = o3d.utility.Vector3dVector(pred_rgb.detach().cpu().numpy())\n",
        "    pcd.normals = o3d.utility.Vector3dVector(nrm_dsdf)\n",
        "    rotated_pcds.append(pcd)\n",
        "    \n",
        "    cylinder_segments = line_set_mesh(rotated_box)\n",
        "    # draw 3D bounding boxes around the object\n",
        "    for k in range(len(cylinder_segments)):\n",
        "      rotated_pcds.append(cylinder_segments[k])\n",
        "\n",
        "    # draw 3D coordinate frames around each object\n",
        "    mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
        "    T = abs_pose_outputs[j].camera_T_object\n",
        "    mesh_t = mesh_frame.transform(T)\n",
        "    rotated_pcds.append(mesh_t)\n",
        "    \n",
        "    points_mesh = camera.convert_points_to_homopoints(rotated_pc.T)\n",
        "    points_2d.append(project(_CAMERA.K_matrix, points_mesh).T)\n",
        "    #2D output\n",
        "    points_obb = camera.convert_points_to_homopoints(np.array(rotated_box).T)\n",
        "    box_obb.append(project(_CAMERA.K_matrix, points_obb).T)\n",
        "    xyz_axis = 0.3*np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0]]).transpose()\n",
        "    sRT = abs_pose_outputs[j].camera_T_object @ abs_pose_outputs[j].scale_matrix\n",
        "    transformed_axes = transform_coordinates_3d(xyz_axis, sRT)\n",
        "    axes.append(calculate_2d_projections(transformed_axes, _CAMERA.K_matrix[:3,:3]))\n",
        "draw_geometries(rotated_pcds)"
      ],
      "metadata": {
        "id": "qUj5pFp5gSLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_img = np.copy(img_vis) \n",
        "projected_points_img = show_projected_points(color_img, points_2d)\n",
        "colors_box = [(63, 237, 234)]\n",
        "im = np.array(np.copy(img_vis)).copy()\n",
        "for k in range(len(colors_box)):\n",
        "    for points_2d, axis in zip(box_obb, axes):\n",
        "        points_2d = np.array(points_2d)\n",
        "        im = draw_bboxes(im, points_2d, axis, colors_box[k])\n",
        "\n",
        "plt.gca().invert_yaxis()\n",
        "plt.axis('off')\n",
        "plt.imshow(im[...,::-1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "twkG5eM1gUoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape Appearance and Pose Optimization\n"
      ],
      "metadata": {
        "id": "wT9ExocDg_dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimization_out = {}\n",
        "latent_opt = []\n",
        "RT_opt = []\n",
        "scale_opt = []\n",
        "\n",
        "do_optim = True    \n",
        "latent_opt = []\n",
        "RT_opt = []\n",
        "scale_opt = []\n",
        "appearance_opt = []\n",
        "colored_opt_pcds = []\n",
        "colored_opt_meshes = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "psi, theta, phi, t = (0, 0, 0, 0)\n",
        "shape_latent_noise = np.random.normal(loc=0, scale=0.02, size=64)\n",
        "add_noise = False\n",
        "viz_type = None\n",
        "\n",
        "# get masks and masked pointclouds of each object in the image\n",
        "depth_ = np.array(depth, dtype=np.float32)*255.0\n",
        "seg_output.convert_to_numpy_from_torch()\n",
        "masks_out = get_masks_out(seg_output, depth_)\n",
        "masks_out = get_aligned_masks_segout(masks_out, output_indices, depth_)\n",
        "masked_pointclouds, areas, masked_rgb = get_masked_textured_pointclouds(masks_out, depth_, left_linear[:,:,::-1], camera = _CAMERA)\n"
      ],
      "metadata": {
        "id": "w9e46uAvhCgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to draw textured shape with absolute pose after optimization loop\n",
        "def draw_colored_shape(emb, abs_pose, appearance_emb, rgbnet, sdf_latent_code_dir, is_oct_grid= False):\n",
        "    if is_oct_grid:\n",
        "        lod = 7\n",
        "        pcd_dsdf, nrm_dsdf = get_surface_pointclouds_octgrid_viz(emb, lod=lod, sdf_latent_code_dir = sdf_latent_code_dir)\n",
        "    else:\n",
        "        pcd_dsdf = get_surface_pointclouds(emb)\n",
        "\n",
        "    pred_rgb = get_rgb_from_rgbnet(emb, pcd_dsdf, appearance_emb, rgbnet)\n",
        "    #pred_rgb = get_rgb(emb, pcd_dsdf, appearance_emb)\n",
        "\n",
        "    rotated_pc, rotated_box, _ = get_pc_absposes(abs_pose, pcd_dsdf)\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(np.copy(rotated_pc))\n",
        "    pcd.colors = o3d.utility.Vector3dVector(pred_rgb.detach().cpu().numpy())\n",
        "    pcd.normals = o3d.utility.Vector3dVector(nrm_dsdf)\n",
        "    return pcd"
      ],
      "metadata": {
        "id": "SrNjMh8fhRpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Core optimization loop\n",
        "for k in range(len(shape_emb_outputs)):\n",
        "  print(\"Starting optimization, object:\", k, \"\\n\", \"----------------------------\", \"\\n\")\n",
        "  if viz_type is not None:\n",
        "      optim_foldername = str(output_path) + '/optim_images_'+str(k)\n",
        "      if not os.path.exists(optim_foldername):\n",
        "          os.makedirs(optim_foldername)\n",
        "  else:\n",
        "    optim_foldername = None\n",
        "  \n",
        "  #optimization starts here:\n",
        "  abs_pose = abs_pose_outputs[k]\n",
        "  mask_area = areas[k]\n",
        "  RT, s = get_abs_pose_vector_from_matrix(abs_pose.camera_T_object, abs_pose.scale_matrix, add_noise = False)\n",
        "\n",
        "  if masked_pointclouds[k] is not None:\n",
        "    shape_emb = shape_emb_outputs[k]\n",
        "    appearance_emb = appearance_emb_outputs[k]\n",
        "    decoder = get_sdfnet(sdf_latent_code_dir = sdf_pretrained_dir)\n",
        "    rgbnet = get_rgbnet(rgb_model_dir)\n",
        "    params = {}\n",
        "    weights = {}\n",
        "\n",
        "    if add_noise:\n",
        "      shape_emb += shape_latent_noise\n",
        "\n",
        "    #Set latent vectors/abs pose to optimize here\n",
        "    params['latent'] = shape_emb\n",
        "    params['RT'] = RT\n",
        "    params['scale'] = np.array(s)\n",
        "    params['appearance'] = appearance_emb\n",
        "    weights['3d'] = 1\n",
        "\n",
        "    optimizer = Optimizer(params, rgbnet, device, weights, mask_area)\n",
        "    # Optimize the initial pose estimate\n",
        "    iters_optim = 200\n",
        "    optimizer.optimize_oct_grid(\n",
        "        iters_optim,\n",
        "        masked_pointclouds[k],\n",
        "        masked_rgb[k],\n",
        "        decoder,\n",
        "        rgbnet, \n",
        "        optim_foldername, \n",
        "        viz_type=viz_type\n",
        "    )\n",
        "\n",
        "    #save latent vectors after optimization\n",
        "    latent_opt.append(params['latent'].detach().cpu().numpy())\n",
        "    RT_opt.append(params['RT'].detach().cpu().numpy())\n",
        "    scale_opt.append(params['scale'].detach().cpu().numpy())\n",
        "    appearance_opt.append(params['appearance'].detach().cpu().numpy())\n",
        "    abs_pose = get_abs_pose_from_vector(params['RT'].detach().cpu().numpy(), params['scale'].detach().cpu().numpy())\n",
        "    obj_colored = draw_colored_shape(params['latent'].detach().cpu().numpy(), abs_pose, params['appearance'].detach().cpu().numpy(), rgbnet, sdf_pretrained_dir, is_oct_grid=True)\n",
        "    colored_opt_pcds.append(obj_colored)\n",
        "  else:\n",
        "    latent_opt.append(shape_emb_outputs[k])\n",
        "    RT_opt.append(RT)\n",
        "    scale_opt.append(np.array(s))\n",
        "    appearance_opt.append(appearance_emb_outputs[k])\n",
        "    print(\"Done with optimization, object:\", k, \"\\n\", \"----------------------------\", \"\\n\")"
      ],
      "metadata": {
        "id": "HbwlR7o_hURJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_geometries(colored_opt_pcds)"
      ],
      "metadata": {
        "id": "wEwXFXfMhYMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "69158ccfe43d0b962045f592ede11796dd42f250837ab62152c8bc6cd100a15b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}