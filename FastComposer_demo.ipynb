{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze17Whr66OiC"
      },
      "source": [
        "論文<br>\n",
        "https://arxiv.org/abs/2305.10431<br>\n",
        "<br>\n",
        "GitHub<br>\n",
        "https://github.com/mit-han-lab/fastcomposer<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/FastComposer_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOLKpkBa6OiI"
      },
      "source": [
        "# setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz8gTEgP6OiJ"
      },
      "source": [
        "## git clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO7I9ozfFpmW"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/mit-han-lab/fastcomposer.git\n",
        "%cd /content/fastcomposer\n",
        "# Commits on Jul 4, 2023\n",
        "!git checkout 106cf26158524c34d3d82ab0016da3b85c4e42c0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07hg4xM8tYCV"
      },
      "source": [
        "## install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRHm5XmrGGNB"
      },
      "outputs": [],
      "source": [
        "%cd /content/fastcomposer\n",
        "\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118\n",
        "!pip install transformers==4.25.1 accelerate datasets evaluate diffusers==0.16.1 xformers triton scipy clip\n",
        "\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E2Tf5qE7EjH"
      },
      "source": [
        "# download pretrain models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHJjZa2Z7Juh"
      },
      "outputs": [],
      "source": [
        "%cd /content/fastcomposer\n",
        "\n",
        "# create dir\n",
        "!mkdir -p model/fastcomposer\n",
        "\n",
        "# download model\n",
        "!wget -c https://huggingface.co/mit-han-lab/fastcomposer/resolve/main/pytorch_model.bin \\\n",
        "      -O model/fastcomposer/pytorch_model.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dz8puomaCYS"
      },
      "source": [
        "# setup image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R4eyeeEaD10"
      },
      "outputs": [],
      "source": [
        "%cd /content/fastcomposer\n",
        "\n",
        "target_a = 'man'\n",
        "target_b = 'women'\n",
        "rootdir = f'input_imgs/{target_a}_{target_b}'\n",
        "dir_a = f'input_imgs/{target_a}_{target_b}/{target_a}'\n",
        "dir_b = f'input_imgs/{target_a}_{target_b}/{target_b}'\n",
        "filename_a = f'{dir_a}/0.jpg'\n",
        "filename_b = f'{dir_b}/0.jpg'\n",
        "\n",
        "!rm -rf {rootdir}\n",
        "!mkdir -p {dir_a}\n",
        "!mkdir -p {dir_b}\n",
        "\n",
        "\n",
        "!wget -c https://cdn.shopify.com/s/files/1/0250/3976/5585/files/gandhi_1024x1024.jpg \\\n",
        "      -O {filename_a}\n",
        "\n",
        "!wget -c https://providence-blue.com/wp-content/uploads/2018/08/florence-nightingale-facts-featured.jpg \\\n",
        "      -O {filename_b}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qMysac8bpxd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "# input image\n",
        "ax0 = fig.add_subplot(1, 2, 1)\n",
        "plt.title('bach', fontsize=16)\n",
        "ax0.axis('off')\n",
        "ax0.imshow( Image.open(filename_a) )\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 2)\n",
        "plt.title('beethoven', fontsize=16)\n",
        "ax1.axis('off')\n",
        "ax1.imshow( Image.open(filename_b) )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vywlOCr-VIKg"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFJ8ytbmkYzz"
      },
      "outputs": [],
      "source": [
        "%cd /content/fastcomposer\n",
        "\n",
        "!sed -E \"s/accelerator.device/\\\"cuda\\\"/g\" -i /content/fastcomposer/fastcomposer/inference.py\n",
        "!sed -E \"s/map_location=\\\"cpu\\\"/map_location=\\\"cuda\\\"/g\" -i /content/fastcomposer/fastcomposer/inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfvHgkDVHvl"
      },
      "outputs": [],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()\n",
        "\n",
        "output_dir = f'output_imgs/{target_a}_{target_b}'\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 accelerate launch \\\n",
        "    --mixed_precision=fp16 \\\n",
        "    fastcomposer/inference.py \\\n",
        "    --pretrained_model_name_or_path \"runwayml/stable-diffusion-v1-5\" \\\n",
        "    --finetuned_model_path \"model/fastcomposer\" \\\n",
        "    --test_reference_folder {rootdir} \\\n",
        "    --test_caption \"a man <|image|> and a beautiful woman <|image|> are cooking with wearing an apron, 4k, detail\" \\\n",
        "    --output_dir {output_dir} \\\n",
        "    --mixed_precision fp16 \\\n",
        "    --image_encoder_type clip \\\n",
        "    --image_encoder_name_or_path \"openai/clip-vit-large-patch14\" \\\n",
        "    --num_image_tokens 1 \\\n",
        "    --max_num_objects 2 \\\n",
        "    --object_resolution 224 \\\n",
        "    --generate_height 512 \\\n",
        "    --generate_width 512 \\\n",
        "    --num_images_per_prompt 5 \\\n",
        "    --num_rows 1 \\\n",
        "    --seed 9258305 \\\n",
        "    --guidance_scale 4 \\\n",
        "    --inference_steps 50 \\\n",
        "    --start_merge_step 10 \\\n",
        "    --no_object_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8S32H4T6nQ7"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  fig = plt.figure(figsize=(15, 10))\n",
        "  # input image\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  plt.title('result', fontsize=16)\n",
        "  ax.axis('off')\n",
        "  ax.imshow( Image.open(f'{output_dir}/output_{i}.png') )\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "69158ccfe43d0b962045f592ede11796dd42f250837ab62152c8bc6cd100a15b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}