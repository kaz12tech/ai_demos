{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9fueCPLFKin"
      },
      "source": [
        "GitHub<br>\n",
        "https://github.com/seasonSH/SemanticStyleGAN<br>\n",
        "論文<br>\n",
        "https://arxiv.org/abs/2112.02236<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/SemanticStyleGAN.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "894c0QeEFKit"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWBmluQQx-MK"
      },
      "source": [
        "## GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyLiFmW6x_3w"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmL3LoMMGcNF"
      },
      "source": [
        "## Githubからソースコード取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tthUF7D6FKiu"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/seasonSH/SemanticStyleGAN.git\n",
        "# for align face\n",
        "!git clone https://github.com/adamian98/pulse.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2Fh1sOHdnn"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP8SsHYvHfkR"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "# ninja\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip > /dev/null\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/ > /dev/null\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force > /dev/null\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erWKHaFdxqnG"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qtaoir3xs6m"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import shutil\n",
        "import numpy as np\n",
        "import imageio\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from models import make_model\n",
        "from visualize.utils import generate, cubic_spline_interpolate\n",
        "\n",
        "from criteria.lpips import lpips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRBoab25xtgl"
      },
      "source": [
        "# 学習済みモデルのセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cSMMFMwx2P5"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "!mkdir pretrained\n",
        "\n",
        "if not os.path.exists('./pretrained/CelebAMask-HQ-512x512.pt'):\n",
        "  !wget -c https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/CelebAMask-HQ-512x512.pt \\\n",
        "        -O ./pretrained/CelebAMask-HQ-512x512.pt\n",
        "if not os.path.exists('./pretrained/BitMoji-512x512.pt'):\n",
        "  !wget -c https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/BitMoji-512x512.pt \\\n",
        "        -O ./pretrained/BitMoji-512x512.pt\n",
        "if not os.path.exists('./pretrained/MetFaces-512x512.pt'):\n",
        "  !wget -c https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/MetFaces-512x512.pt \\\n",
        "        -O ./pretrained/MetFaces-512x512.pt\n",
        "if not os.path.exists('./pretrained/Toonify-512x512.pt'):\n",
        "  !wget -c https://github.com/seasonSH/SemanticStyleGAN/releases/download/1.0.0/Toonify-512x512.pt \\\n",
        "        -O ./pretrained/Toonify-512x512.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BB4TY8OyFkw"
      },
      "source": [
        "# Random Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33NmdnMnyI5T"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "\n",
        "args.ckpt = './pretrained/CelebAMask-HQ-512x512.pt'\n",
        "args.outdir = './results/samples'\n",
        "args.batch = 8\n",
        "args.sample = 20\n",
        "args.truncation = 0.7\n",
        "args.truncation_mean = 10000\n",
        "args.save_latent = True\n",
        "args.device = 'cuda'\n",
        "\n",
        "if os.path.exists(args.outdir):\n",
        "  shutil.rmtree(args.outdir)\n",
        "os.makedirs(args.outdir)\n",
        "\n",
        "print(\"Loading model ...\")\n",
        "ckpt = torch.load(args.ckpt)\n",
        "model = make_model(ckpt['args'])\n",
        "model.to(args.device)\n",
        "model.eval()\n",
        "model.load_state_dict(ckpt['g_ema'])\n",
        "mean_latent = model.style(torch.randn(args.truncation_mean, model.style_dim, device=args.device)).mean(0)\n",
        "\n",
        "print(\"Generating images ...\")\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "  styles = model.style(torch.randn(args.sample, model.style_dim, device=args.device))\n",
        "  styles = args.truncation * styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "  images, segs = generate(model, styles, mean_latent=mean_latent, batch_size=args.batch)\n",
        "  for i in range(len(images)):\n",
        "    imageio.imwrite(f\"{args.outdir}/{str(i).zfill(6)}_img.jpg\", images[i])\n",
        "    imageio.imwrite(f\"{args.outdir}/{str(i).zfill(6)}_seg.jpg\", segs[i])\n",
        "    if args.save_latent:\n",
        "      np.save(f'{args.outdir}/{str(i).zfill(6)}_latent.npy', styles[i:i+1].cpu().numpy())\n",
        "print(f\"Average speed: {(time.time() - start_time)/(args.sample)}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkrUYs9x8Fhg"
      },
      "source": [
        "# Generate Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzkjZ9Bm9BKa"
      },
      "outputs": [],
      "source": [
        "latent_dict_celeba = {\n",
        "  2:  \"bcg_1\",\n",
        "  3:  \"bcg_2\",\n",
        "  4:  \"face_shape\",\n",
        "  5:  \"face_texture\",\n",
        "  6:  \"eye_shape\",\n",
        "  7:  \"eye_texture\",\n",
        "  8:  \"eyebrow_shape\",\n",
        "  9:  \"eyebrow_texture\",\n",
        "  10: \"mouth_shape\",\n",
        "  11: \"mouth_texture\",\n",
        "  12: \"nose_shape\",\n",
        "  13: \"nose_texture\",\n",
        "  14: \"ear_shape\",\n",
        "  15: \"ear_texture\",\n",
        "  16: \"hair_shape\",\n",
        "  17: \"hair_texture\",\n",
        "  18: \"neck_shape\",\n",
        "  19: \"neck_texture\",\n",
        "  20: \"cloth_shape\",\n",
        "  21: \"cloth_texture\",\n",
        "  22: \"glass\",\n",
        "  24: \"hat\",\n",
        "  26: \"earing\",\n",
        "  0:  \"coarse_1\",\n",
        "  1:  \"coarse_2\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohMF7Y8f8O2r"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "\n",
        "args.ckpt = './pretrained/CelebAMask-HQ-512x512.pt'\n",
        "args.latent = './results/samples/000000_latent.npy'\n",
        "args.outdir = './results/videos'\n",
        "args.batch = 8\n",
        "args.sample = 10\n",
        "args.steps = 160\n",
        "args.truncation = 0.7\n",
        "args.truncation_mean = 10000\n",
        "args.dataset_name = 'celeba'\n",
        "args.device = 'cuda'\n",
        "\n",
        "\n",
        "if os.path.exists(args.outdir):\n",
        "  shutil.rmtree(args.outdir)\n",
        "os.makedirs(args.outdir)\n",
        "\n",
        "print(\"Loading model ...\")\n",
        "ckpt = torch.load(args.ckpt)\n",
        "model = make_model(ckpt['args'])\n",
        "model.to(args.device)\n",
        "model.eval()\n",
        "model.load_state_dict(ckpt['g_ema'])\n",
        "mean_latent = model.style(torch.randn(args.truncation_mean, model.style_dim, device=args.device)).mean(0)\n",
        "\n",
        "print(\"Generating original image ...\")\n",
        "with torch.no_grad():\n",
        "  if args.latent is None:\n",
        "    styles = model.style(torch.randn(1, model.style_dim, device=args.device))\n",
        "    styles = args.truncation * styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "  else:\n",
        "    styles = torch.tensor(np.load(args.latent), device=args.device)\n",
        "  if styles.ndim == 2:\n",
        "    assert styles.size(1) == model.style_dim\n",
        "    styles = styles.unsqueeze(1).repeat(1, model.n_latent, 1)\n",
        "  images, segs = generate(model, styles, mean_latent=mean_latent, randomize_noise=False)\n",
        "  imageio.imwrite(f'{args.outdir}/image.jpeg', images[0])\n",
        "  imageio.imwrite(f'{args.outdir}/seg.jpeg', segs[0])\n",
        "print(\"Generating videos ...\")\n",
        "if args.dataset_name == \"celeba\":\n",
        "  latent_dict = latent_dict_celeba\n",
        "else:\n",
        "  raise ValueError(\"Unknown dataset name: f{args.dataset_name}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  for latent_index, latent_name in latent_dict.items():\n",
        "    styles_new = styles.repeat(args.sample, 1, 1)\n",
        "    mix_styles = model.style(torch.randn(args.sample, 512, device=args.device))\n",
        "    mix_styles[-1] = mix_styles[0]\n",
        "    mix_styles = args.truncation * mix_styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "    mix_styles = mix_styles.unsqueeze(1).repeat(1,model.n_latent,1)\n",
        "    styles_new[:,latent_index] = mix_styles[:,latent_index]\n",
        "    styles_new = cubic_spline_interpolate(styles_new, step=args.steps)\n",
        "    images, segs = generate(model, styles_new, mean_latent=mean_latent, randomize_noise=False, batch_size=args.batch)\n",
        "    frames = [np.concatenate((img,seg),1) for (img,seg) in zip(images,segs)]\n",
        "    imageio.mimwrite(f'{args.outdir}/{latent_index:02d}_{latent_name}.mp4', frames, fps=20)\n",
        "    print(f\"{args.outdir}/{latent_index:02d}_{latent_name}.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXAa1h2L_t7o"
      },
      "source": [
        "# videoの表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZboID-c_v3-"
      },
      "outputs": [],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR5GBR11_48N"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.fx.resize import resize\n",
        "\n",
        "concat_video = './results/videos/concat.mp4'\n",
        "\n",
        "clip1 = VideoFileClip('/content/SemanticStyleGAN/results/videos/04_face_shape.mp4')\n",
        "clip2 = VideoFileClip('/content/SemanticStyleGAN/results/videos/06_eye_shape.mp4')\n",
        "clip3 = VideoFileClip('/content/SemanticStyleGAN/results/videos/10_mouth_shape.mp4')\n",
        "clip4 = VideoFileClip('/content/SemanticStyleGAN/results/videos/18_neck_shape.mp4')\n",
        "clip5 = VideoFileClip('/content/SemanticStyleGAN/results/videos/16_hair_shape.mp4')\n",
        "clip6 = VideoFileClip('/content/SemanticStyleGAN/results/videos/17_hair_texture.mp4')\n",
        "\n",
        "concat = clips_array([[clip1, clip2], [clip3, clip4], [clip5, clip6]])\n",
        "concat.write_videofile(concat_video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_r-Q_atDdmB"
      },
      "outputs": [],
      "source": [
        "concat = resize(concat, width=640)\n",
        "concat.ipython_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjPXbvvPgpDv"
      },
      "source": [
        "# invert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfdcdzM-grCg"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "!rm -rf test_img\n",
        "!mkdir -p test_img/src test_img/align\n",
        "\n",
        "!wget -c https://www.pakutaso.com/shared/img/thumb/kuchikomi725_TP_V.jpg \\\n",
        "      -O ./test_img/src/test1.jpg\n",
        "\n",
        "%cd /content/pulse\n",
        "!python align_face.py \\\n",
        "  -input_dir /content/SemanticStyleGAN/test_img/src \\\n",
        "  -output_dir /content/SemanticStyleGAN/test_img/align \\\n",
        "  -output_size 512 \\\n",
        "  -seed 12 \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_j3fXxcg6L1"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "!cp visualize/invert.py invert.py\n",
        "\n",
        "!python invert.py \\\n",
        "  --ckpt pretrained/CelebAMask-HQ-512x512.pt \\\n",
        "  --imgdir test_img/align \\\n",
        "  --outdir results/inversion \\\n",
        "  --size 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86YjSPjymbou"
      },
      "source": [
        "# generate image Bitmoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx31UrV7mgC3"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "\n",
        "args.ckpt = './pretrained/BitMoji-512x512.pt'\n",
        "args.latent = './results/inversion/latent/test1_0.npy'\n",
        "args.outdir = './results/style_BitMoji'\n",
        "args.truncation = 0.7\n",
        "args.truncation_mean = 10000\n",
        "args.device = 'cuda'\n",
        "\n",
        "if os.path.exists(args.outdir):\n",
        "  shutil.rmtree(args.outdir)\n",
        "os.makedirs(args.outdir)\n",
        "\n",
        "print(\"Loading model ...\")\n",
        "ckpt = torch.load(args.ckpt)\n",
        "model = make_model(ckpt['args'])\n",
        "model.to(args.device)\n",
        "model.eval()\n",
        "model.load_state_dict(ckpt['g_ema'])\n",
        "mean_latent = model.style(torch.randn(args.truncation_mean, model.style_dim, device=args.device)).mean(0)\n",
        "\n",
        "print(\"Generating original image ...\")\n",
        "with torch.no_grad():\n",
        "  if args.latent is None:\n",
        "    styles = model.style(torch.randn(1, model.style_dim, device=args.device))\n",
        "    styles = args.truncation * styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "  else:\n",
        "    styles = torch.tensor(np.load(args.latent), device=args.device)\n",
        "  if styles.ndim == 2:\n",
        "    assert styles.size(1) == model.style_dim\n",
        "    styles = styles.unsqueeze(1).repeat(1, model.n_latent, 1)\n",
        "  images, segs = generate(model, styles, mean_latent=mean_latent, randomize_noise=False)\n",
        "  imageio.imwrite(f'{args.outdir}/image.jpeg', images[0])\n",
        "  imageio.imwrite(f'{args.outdir}/seg.jpeg', segs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcfeGTFrE5N"
      },
      "source": [
        "# generate image MetfFaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSxA0blLrEDQ"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "\n",
        "args.ckpt = './pretrained/MetFaces-512x512.pt'\n",
        "args.latent = './results/inversion/latent/test1_0.npy'\n",
        "args.outdir = './results/style_MetFaces'\n",
        "args.truncation = 0.7\n",
        "args.truncation_mean = 10000\n",
        "args.device = 'cuda'\n",
        "\n",
        "if os.path.exists(args.outdir):\n",
        "  shutil.rmtree(args.outdir)\n",
        "os.makedirs(args.outdir)\n",
        "\n",
        "print(\"Loading model ...\")\n",
        "ckpt = torch.load(args.ckpt)\n",
        "model = make_model(ckpt['args'])\n",
        "model.to(args.device)\n",
        "model.eval()\n",
        "model.load_state_dict(ckpt['g_ema'])\n",
        "mean_latent = model.style(torch.randn(args.truncation_mean, model.style_dim, device=args.device)).mean(0)\n",
        "\n",
        "print(\"Generating original image ...\")\n",
        "with torch.no_grad():\n",
        "  if args.latent is None:\n",
        "    styles = model.style(torch.randn(1, model.style_dim, device=args.device))\n",
        "    styles = args.truncation * styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "  else:\n",
        "    styles = torch.tensor(np.load(args.latent), device=args.device)\n",
        "  if styles.ndim == 2:\n",
        "    assert styles.size(1) == model.style_dim\n",
        "    styles = styles.unsqueeze(1).repeat(1, model.n_latent, 1)\n",
        "  images, segs = generate(model, styles, mean_latent=mean_latent, randomize_noise=False)\n",
        "  imageio.imwrite(f'{args.outdir}/image.jpeg', images[0])\n",
        "  imageio.imwrite(f'{args.outdir}/seg.jpeg', segs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Zwr9_mNrR4g"
      },
      "outputs": [],
      "source": [
        "%cd /content/SemanticStyleGAN\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "\n",
        "args.ckpt = './pretrained/Toonify-512x512.pt'\n",
        "args.latent = './results/inversion/latent/test1_0.npy'\n",
        "args.outdir = './results/style_Toonify'\n",
        "args.truncation = 0.7\n",
        "args.truncation_mean = 10000\n",
        "args.device = 'cuda'\n",
        "\n",
        "if os.path.exists(args.outdir):\n",
        "  shutil.rmtree(args.outdir)\n",
        "os.makedirs(args.outdir)\n",
        "\n",
        "print(\"Loading model ...\")\n",
        "ckpt = torch.load(args.ckpt)\n",
        "model = make_model(ckpt['args'])\n",
        "model.to(args.device)\n",
        "model.eval()\n",
        "model.load_state_dict(ckpt['g_ema'])\n",
        "mean_latent = model.style(torch.randn(args.truncation_mean, model.style_dim, device=args.device)).mean(0)\n",
        "\n",
        "print(\"Generating original image ...\")\n",
        "with torch.no_grad():\n",
        "  if args.latent is None:\n",
        "    styles = model.style(torch.randn(1, model.style_dim, device=args.device))\n",
        "    styles = args.truncation * styles + (1-args.truncation) * mean_latent.unsqueeze(0)\n",
        "  else:\n",
        "    styles = torch.tensor(np.load(args.latent), device=args.device)\n",
        "  if styles.ndim == 2:\n",
        "    assert styles.size(1) == model.style_dim\n",
        "    styles = styles.unsqueeze(1).repeat(1, model.n_latent, 1)\n",
        "  images, segs = generate(model, styles, mean_latent=mean_latent, randomize_noise=False)\n",
        "  imageio.imwrite(f'{args.outdir}/image.jpeg', images[0])\n",
        "  imageio.imwrite(f'{args.outdir}/seg.jpeg', segs[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SemanticStyleGAN_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
