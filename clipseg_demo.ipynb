{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuAbH7owBe8n"
      },
      "source": [
        "論文<br>\n",
        "https://arxiv.org/abs/2112.10003<br>\n",
        "<br>\n",
        "GitHub<br>\n",
        "https://github.com/timojl/clipseg<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QM4KH58C0Rs"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_6OZWPQDQYD"
      },
      "source": [
        "## GitHubからCode Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6T88FpxC4Dv",
        "outputId": "6ec1344f-ccaa-4b24-e8a7-bf44b3cc737c"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/timojl/clipseg.git\n",
        "\n",
        "# Commits on Sep 27, 2022\n",
        "%cd /content/clipseg\n",
        "!git checkout 515ca6ec2d066d447240c1dd79f3bbbee685bd29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LY5SjfCDOpp"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaVpgTtEJJ23",
        "outputId": "769d96a9-1070-44d1-9ab9-e8d2759824a3"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqJYBtSnDUIf"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLXTL4qbBTZe",
        "outputId": "bee5b2b7-a4d4-468d-d927-519f23e05599"
      },
      "outputs": [],
      "source": [
        "%cd /content/clipseg\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import requests\n",
        "\n",
        "from models.clipseg import CLIPDensePredT\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using device is\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl2Rhw8DGmRx"
      },
      "source": [
        "# 学習済みモデルのセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSB4lJMXGq4W",
        "outputId": "f61ab9ed-da42-415f-96f1-79ed1f1867ba"
      },
      "outputs": [],
      "source": [
        "%cd /content/clipseg\n",
        "!mkdir pretrained\n",
        "\n",
        "if not os.path.exists('pretrained/weights.zip'):\n",
        "  !wget https://owncloud.gwdg.de/index.php/s/ioHbRzFx6th32hn/download -O pretrained/weights.zip\n",
        "  !unzip -d pretrained/weights -j pretrained/weights.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkZYB5AmG72P"
      },
      "source": [
        "# モデルのロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-rPhn7G-t_",
        "outputId": "fe60f2de-c675-4e9d-cb26-b7688ba0a64a"
      },
      "outputs": [],
      "source": [
        "%cd /content/clipseg\n",
        "\n",
        "# load model\n",
        "model = CLIPDensePredT(version='ViT-B/16', reduce_dim=64)\n",
        "model.eval();\n",
        "\n",
        "model.load_state_dict(torch.load('pretrained/weights/rd64-uni.pth', map_location=torch.device(device)), strict=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f18l3_gtHssj"
      },
      "source": [
        "# データの前処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpN1zfm_K28r",
        "outputId": "baa80d3a-9f30-4b16-8cf4-409a341dc67e"
      },
      "outputs": [],
      "source": [
        "!wget -c https://www.pakutaso.com/shared/img/thumb/kotetsuPAR583412044_TP_V4.jpg \\\n",
        "      -O test_01.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "5cpVmhAiHupQ",
        "outputId": "36f9c65b-99cb-46fc-e4b8-1fe352ffca68"
      },
      "outputs": [],
      "source": [
        "%cd /content/clipseg\n",
        "\n",
        "# 画像のロード\n",
        "input_image = Image.open('test_01.jpg')\n",
        "\n",
        "# Normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Resize((352, 352)),\n",
        "])\n",
        "img = transform(input_image).unsqueeze(0)\n",
        "\n",
        "input_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ZevrMNIF3H"
      },
      "source": [
        "# Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "nLNa9KRjIRUC",
        "outputId": "201525a0-522e-4918-f323-b06bf1d13861"
      },
      "outputs": [],
      "source": [
        "prompts = ['a dog', 'PC']\n",
        "num_of_p = len(prompts)\n",
        "\n",
        "# predict\n",
        "with torch.no_grad():\n",
        "  preds = model(img.repeat(num_of_p,1,1,1), prompts)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "GBizLkJxvpw6",
        "outputId": "0b86566f-fa7e-4a31-abb4-e07702d69106"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(num=None, figsize=(18, 6), dpi=256)\n",
        "\n",
        "for i in range(num_of_p+1):\n",
        "  ax = fig.add_subplot(1, num_of_p+1, i+1, xticks=[], yticks=[])\n",
        "  \n",
        "  if i == 0:\n",
        "    plt.imshow(input_image)\n",
        "    ax.set_title(\"input\")\n",
        "  else:\n",
        "    plt.imshow(torch.sigmoid(preds[i-1][0]))\n",
        "    ax.set_title(prompts[i-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "69158ccfe43d0b962045f592ede11796dd42f250837ab62152c8bc6cd100a15b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
