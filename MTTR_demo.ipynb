{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjT7pu6kcgTT"
      },
      "source": [
        "論文  \n",
        "https://arxiv.org/abs/2111.14821v1<br>\n",
        "<br>\n",
        "GitHub<br>\n",
        "https://github.com/mttr2021/MTTR<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/MTTR_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB2kaHiqcgTY"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOfZX5p-cgTZ"
      },
      "source": [
        "## GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXweX5OacgTa"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koYk5tuIcgTb"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iQcFuf2cgTb"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!pip install av moviepy gdown yt-dlp ruamel.yaml einops timm transformers\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageOps, ImageFont\n",
        "from yt_dlp import YoutubeDL\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# テスト動画のセットアップ"
      ],
      "metadata": {
        "id": "jP2YgbEwcym6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## パラメータ設定"
      ],
      "metadata": {
        "id": "I15IuLIEejVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown テスト動画に使用するYoutubeのリンクを設定してください。\n",
        "video_url = 'https://www.youtube.com/watch?v=YThX7_8I3m0' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 動画の切り抜き範囲(秒)を指定してください。\n",
        "start_sec = 233 #@param {type:\"integer\"}\n",
        "end_sec =  243#@param {type:\"integer\"}\n",
        "\n",
        "#@markdown テキストクエリをカンマ区切りで入力してください。\n",
        "text = \"guy in black performing tricks on a bike,a black bike used to perform tricks\" #@param {type:\"string\"}\n",
        "\n",
        "(start_pt, end_pt) = (start_sec, end_sec)\n",
        "\n",
        "text_queries = text.split(\",\")\n",
        "\n",
        "assert  0 < end_pt - start_pt <= 10, 'error - 動画の長さは10秒以内にしてください。'\n",
        "assert  1 <= len(text_queries) <= 2, 'error - テキストクエリは2個までにしてください。'"
      ],
      "metadata": {
        "id": "wj91Ze8Xc0vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 動画ダウンロード"
      ],
      "metadata": {
        "id": "wdS2CmO8eg-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_resolution = 360\n",
        "full_video_path = 'full_video.mp4'\n",
        "input_clip_path = 'input_clip.mp4'\n",
        "\n",
        "# 動画ダウンロード\n",
        "ydl_opts = {'format': f'best[height<={download_resolution}]', 'overwrites': True, 'outtmpl': full_video_path}\n",
        "with YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([video_url])"
      ],
      "metadata": {
        "id": "6CzoRc0LegbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 切り抜き箇所表示"
      ],
      "metadata": {
        "id": "YJPyuWqvevKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the relevant subclip:\n",
        "with VideoFileClip(full_video_path) as video:\n",
        "    subclip = video.subclip(start_pt, end_pt)\n",
        "    subclip.write_videofile(input_clip_path)\n",
        "    \n",
        "# visualize the input clip:\n",
        "input_clip = open(input_clip_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(input_clip).decode()\n",
        "HTML(\"\"\"<video width=720 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Fa9WfCa-eyqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "KM4bvojNfFg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルのロード"
      ],
      "metadata": {
        "id": "SU41T7VUfJFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, postprocessor = torch.hub.load('mttr2021/MTTR:main','mttr_refer_youtube_vos', force_reload=True)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "jkoHWXBkfLIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NestedTensor(object):\n",
        "    def __init__(self, tensors, mask):\n",
        "        self.tensors = tensors\n",
        "        self.mask = mask\n",
        "\n",
        "def nested_tensor_from_videos_list(videos_list):\n",
        "    def _max_by_axis(the_list):\n",
        "      maxes = the_list[0]\n",
        "      for sublist in the_list[1:]:\n",
        "          for index, item in enumerate(sublist):\n",
        "              maxes[index] = max(maxes[index], item)\n",
        "      return maxes\n",
        "\n",
        "    max_size = _max_by_axis([list(img.shape) for img in videos_list])\n",
        "    padded_batch_shape = [len(videos_list)] + max_size\n",
        "    b, t, c, h, w = padded_batch_shape\n",
        "    dtype = videos_list[0].dtype\n",
        "    device = videos_list[0].device\n",
        "    padded_videos = torch.zeros(padded_batch_shape, dtype=dtype, device=device)\n",
        "    videos_pad_masks = torch.ones((b, t, h, w), dtype=torch.bool, device=device)\n",
        "    for vid_frames, pad_vid_frames, vid_pad_m in zip(videos_list, padded_videos, videos_pad_masks):\n",
        "        pad_vid_frames[:vid_frames.shape[0], :, :vid_frames.shape[2], :vid_frames.shape[3]].copy_(vid_frames)\n",
        "        vid_pad_m[:vid_frames.shape[0], :vid_frames.shape[2], :vid_frames.shape[3]] = False\n",
        "    return NestedTensor(padded_videos.transpose(0, 1), videos_pad_masks.transpose(0, 1))\n",
        "\n",
        "def apply_mask(image, mask, color, transparency=0.7):\n",
        "    mask = mask[..., np.newaxis].repeat(repeats=3, axis=2)\n",
        "    mask = mask * transparency\n",
        "    color_matrix = np.ones(image.shape, dtype=np.float) * color\n",
        "    out_image = color_matrix * mask + image * (1.0 - mask)\n",
        "    return out_image"
      ],
      "metadata": {
        "id": "v8vdRx2bfVhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MTTR"
      ],
      "metadata": {
        "id": "C5STKbzjf_eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_length = 24  # length of window during inference\n",
        "window_overlap = 6  # overlap (in frames) between consecutive windows\n",
        "\n",
        "with torch.inference_mode():\n",
        "  # read and preprocess the video clip:\n",
        "  video, audio, meta = torchvision.io.read_video(filename=input_clip_path)\n",
        "  video = rearrange(video, 't h w c -> t c h w')\n",
        "  input_video = F.resize(video, size=360, max_size=640).cuda()\n",
        "  input_video = input_video.to(torch.float).div_(255)\n",
        "  input_video = F.normalize(input_video, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  video_metadata = {'resized_frame_size': input_video.shape[-2:], 'original_frame_size': video.shape[-2:]}\n",
        "  \n",
        "  # partition the clip into overlapping windows of frames:\n",
        "  windows = [input_video[i:i+window_length] for i in range(0, len(input_video), window_length - window_overlap)]\n",
        "  # clean up the text queries:\n",
        "  text_queries = [\" \".join(q.lower().split()) for q in text_queries]\n",
        "\n",
        "  pred_masks_per_query = []\n",
        "  t, _, h, w = video.shape\n",
        "  for text_query in tqdm(text_queries, desc='text queries'):\n",
        "    pred_masks = torch.zeros(size=(t, 1, h, w))\n",
        "    for i, window in enumerate(tqdm(windows, desc='windows')):\n",
        "      window = nested_tensor_from_videos_list([window])\n",
        "      valid_indices = torch.arange(len(window.tensors)).cuda()\n",
        "      outputs = model(window, valid_indices, [text_query])\n",
        "      window_masks = postprocessor(outputs, [video_metadata], window.tensors.shape[-2:])[0]['pred_masks']\n",
        "      win_start_idx = i*(window_length-window_overlap)\n",
        "      pred_masks[win_start_idx:win_start_idx + window_length] = window_masks\n",
        "    pred_masks_per_query.append(pred_masks)"
      ],
      "metadata": {
        "id": "Fh5U3zbAfwM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentation maskのvisualization"
      ],
      "metadata": {
        "id": "RiXbxlNXgDRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RGB colors for instance masks:\n",
        "light_blue = (41, 171, 226)\n",
        "purple = (237, 30, 121)\n",
        "dark_green = (35, 161, 90)\n",
        "orange = (255, 148, 59)\n",
        "colors = np.array([light_blue, purple, dark_green, orange])\n",
        "\n",
        "# width (in pixels) of the black strip above the video on which the text queries will be displayed:\n",
        "text_border_height_per_query = 36\n",
        "\n",
        "video_np = rearrange(video, 't c h w -> t h w c').numpy() / 255.0\n",
        "# del video\n",
        "pred_masks_per_frame = rearrange(torch.stack(pred_masks_per_query), 'q t 1 h w -> t q h w').numpy()\n",
        "masked_video = []\n",
        "for vid_frame, frame_masks in tqdm(zip(video_np, pred_masks_per_frame), total=len(video_np), desc='applying masks...'):\n",
        "  # apply the masks:\n",
        "  for inst_mask, color in zip(frame_masks, colors):\n",
        "    vid_frame = apply_mask(vid_frame, inst_mask, color / 255.0)\n",
        "  vid_frame = Image.fromarray((vid_frame * 255).astype(np.uint8))\n",
        "  # visualize the text queries:\n",
        "  vid_frame = ImageOps.expand(vid_frame, border=(0, len(text_queries)*text_border_height_per_query, 0, 0))\n",
        "  W, H = vid_frame.size\n",
        "  draw = ImageDraw.Draw(vid_frame)\n",
        "  font = ImageFont.truetype(font='LiberationSans-Regular.ttf', size=30)\n",
        "  for i, (text_query, color) in enumerate(zip(text_queries, colors), start=1):\n",
        "      w, h = draw.textsize(text_query, font=font)\n",
        "      draw.text(((W - w) / 2, (text_border_height_per_query * i) - h - 3),\n",
        "                text_query, fill=tuple(color) + (255,), font=font)\n",
        "  masked_video.append(np.array(vid_frame))\n",
        "\n",
        "# generate and save the output clip:\n",
        "output_clip_path = 'output_clip.mp4'\n",
        "clip = ImageSequenceClip(sequence=masked_video, fps=meta['video_fps'])\n",
        "clip = clip.set_audio(AudioFileClip(input_clip_path))\n",
        "clip.write_videofile(output_clip_path, fps=meta['video_fps'], audio=True)\n",
        "del masked_video"
      ],
      "metadata": {
        "id": "hZ1pbI3OfzHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結果の表示"
      ],
      "metadata": {
        "id": "n2_FJVDdf3Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the output clip:\n",
        "output_clip = open(output_clip_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(output_clip).decode()\n",
        "HTML(\"\"\"<video width=720 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "yFLqDgGEf5ID"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "MTTR_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}