{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9bZg9zMTlZW"
      },
      "source": [
        "論文  \n",
        "https://arxiv.org/abs/2209.14916<br>\n",
        "<br>\n",
        "GitHub<br>\n",
        "https://github.com/GuyTevet/motion-diffusion-model<br>\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/motions_diffusion_model_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkZx8Zrj--z1"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETA7G8-9TlZc"
      },
      "source": [
        "## ランタイムの設定\n",
        "「ランタイム」→「ランタイムのタイプを変更」→「ハードウェアアクセラレータ」をGPUに変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC0ghLSMTlZd"
      },
      "source": [
        "## 実行方法\n",
        "「ランタイム」→「すべてのセルを実行」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGVQtScR_CBd"
      },
      "source": [
        "## GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYSww9QJTlZe",
        "outputId": "287e7ddc-7da4-4fc2-b239-697a3e109cdc"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2QX6ac2_E_S"
      },
      "source": [
        "## GitHubからコード取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgvLy-kp_Ff1",
        "outputId": "9662c595-7a88-4df8-8a0f-e0324791a1cf"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/GuyTevet/motion-diffusion-model.git\n",
        "\n",
        "# Commits on Oct 10, 2022使用\n",
        "%cd /content/motion-diffusion-model\n",
        "!git checkout c5c0ae13974c110cb6ea8292dc88da28d3d78854"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOAJsAW3TlZg"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcZzKaXGTlZh",
        "outputId": "36fc6b78-e7ee-4a03-9b1f-5440859dca26"
      },
      "outputs": [],
      "source": [
        "%cd /content/motion-diffusion-model\n",
        "\n",
        "!pip install --upgrade gdown\n",
        "!pip install smplx chumpy trimesh\n",
        "!pip install moviepy imageio==2.4.1\n",
        "!pip install --upgrade gdown\n",
        "\n",
        "!python -m spacy==3.4.1 download en_core_web_sm\n",
        "!pip install git+https://github.com/openai/CLIP.git@d50d76daa670286dd6cacf3bcd80b5e4823fc8e1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR-bW8rJ_ZEE"
      },
      "source": [
        "## SMPL、Human3Dなどデータセットダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNGuloAa_j5L",
        "outputId": "10b40977-b241-4546-cb53-85378db426c5"
      },
      "outputs": [],
      "source": [
        "%cd /content/motion-diffusion-model\n",
        "\n",
        "# Download SMPL\n",
        "!bash prepare/download_smpl_files.sh\n",
        "!bash prepare/download_glove.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWAHUvAY_nCj",
        "outputId": "71d4e980-9870-41e1-a59a-b7ecc0a48f05"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "# Download Human3D\n",
        "!git clone https://github.com/EricGuo5513/HumanML3D.git\n",
        "!unzip ./HumanML3D/HumanML3D/texts.zip -d ./HumanML3D/HumanML3D/ > /dev/null\n",
        "!cp -r HumanML3D/HumanML3D motion-diffusion-model/dataset/HumanML3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAHVfxml_rdz"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNl_ilt_toe",
        "outputId": "7e55b713-320b-4bd5-861f-e3abc6e69e7c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from moviepy.video.fx.resize import resize\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip, CompositeAudioClip\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9fxFSgQ_vXa"
      },
      "source": [
        "# 学習済みモデルのセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V14-mrpy_xJZ",
        "outputId": "f8e5f470-1c00-4c7a-d42a-23adf1275b6f"
      },
      "outputs": [],
      "source": [
        "%cd /content/motion-diffusion-model\n",
        "\n",
        "if not os.path.exists('humanml_trans_enc_512.zip'):\n",
        "  !gdown 'https://drive.google.com/uc?id=1PE0PK8e5a5j-7-Xhs5YET5U5pGh0c821'\n",
        "\n",
        "!unzip humanml_trans_enc_512.zip -d ./pretrained/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSirIKGX_zhD"
      },
      "source": [
        "# Text to Human Motion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3niOiaDABKO"
      },
      "outputs": [],
      "source": [
        "prompt = \"The person suddenly dances while walking.\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w67QI7ak_1QN",
        "outputId": "94766a02-72e3-4a04-bcbd-7d5096154d4f"
      },
      "outputs": [],
      "source": [
        "!python -m sample \\\n",
        "  --model_path ./pretrained/humanml_trans_enc_512/model000200000.pt \\\n",
        "  --text_prompt '{prompt}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR2RgCJN_2tO"
      },
      "source": [
        "## 出力結果を表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTW2i4TWAT0p"
      },
      "outputs": [],
      "source": [
        "foldername = prompt.replace(\" \", \"_\")\n",
        "foldername = foldername.replace(\".\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Xmodem_4Zj"
      },
      "outputs": [],
      "source": [
        "base_path = f'/content/motion-diffusion-model/pretrained/humanml_trans_enc_512/samples_humanml_trans_enc_512_000200000_seed10_{foldername}/'\n",
        "out_motion_video0 = base_path + \"sample00_rep00.mp4\"\n",
        "out_motion_video1 = base_path + \"sample00_rep01.mp4\"\n",
        "out_motion_video2 = base_path + \"sample00_rep02.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "8UpMCRUb_82M",
        "outputId": "296db049-1747-47ff-c7b9-4a2c192f3b37"
      },
      "outputs": [],
      "source": [
        "clip = VideoFileClip(out_motion_video0)\n",
        "clip = resize(clip, height=420)\n",
        "clip.ipython_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "5lH4HjKl_5vT",
        "outputId": "87a771bb-9c51-42c1-dc5f-170207d3b12f"
      },
      "outputs": [],
      "source": [
        "clip = VideoFileClip(out_motion_video1)\n",
        "clip = resize(clip, height=420)\n",
        "clip.ipython_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "DW1pJkgq_7Yl",
        "outputId": "ddae7fed-1b47-48f7-86c8-3a4181566e34"
      },
      "outputs": [],
      "source": [
        "clip = VideoFileClip(out_motion_video2)\n",
        "clip = resize(clip, height=420)\n",
        "clip.ipython_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aro-wMmmAi8u"
      },
      "source": [
        "# Rendering SMPL Mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF0_4dfNBDaz",
        "outputId": "d22d2df2-bd6f-4131-918d-209a43e97060"
      },
      "outputs": [],
      "source": [
        "!python -m visualize.render_mesh \\\n",
        "  --input_path=$out_motion_video0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzi6cQj2BFtF"
      },
      "source": [
        "## Rendering Objファイル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1tNCyorBJ1S",
        "outputId": "378b5450-0755-4a32-bf53-b538163e34af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p9V7Tq1BLIn",
        "outputId": "4841ddc0-4c7e-4055-bf32-d660bdb63c2f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Util function for loading meshes\n",
        "from pytorch3d.io import load_objs_as_meshes, load_obj\n",
        "\n",
        "# Data structures and functions for rendering\n",
        "from pytorch3d.structures import Meshes\n",
        "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
        "from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVPerspectiveCameras, \n",
        "    PointLights, \n",
        "    DirectionalLights, \n",
        "    Materials, \n",
        "    RasterizationSettings, \n",
        "    MeshRenderer, \n",
        "    MeshRasterizer,  \n",
        "    SoftPhongShader,\n",
        "    TexturesUV,\n",
        "    TexturesVertex\n",
        ")\n",
        "\n",
        "# add path for demo utils functions \n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(''))\n",
        "\n",
        "!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
        "from plot_image_grid import image_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYCcDNHHBNqw",
        "outputId": "032097e1-a30b-4bf0-e100-ca105368d2a9"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "obj_filename = f'/content/motion-diffusion-model/pretrained/humanml_trans_enc_512/samples_humanml_trans_enc_512_000200000_seed10_{foldername}/sample00_rep00_obj/frame102.obj'\n",
        "\n",
        "# Load obj file\n",
        "mesh = load_objs_as_meshes([obj_filename], device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rqxwZ0tYBYtl",
        "outputId": "050887c7-0f6d-4eef-eebf-5dacaae997bf"
      },
      "outputs": [],
      "source": [
        "verts, faces_idx, _ = load_obj(obj_filename)\n",
        "faces = faces_idx.verts_idx\n",
        "\n",
        "# Initialize each vertex to be white in color.\n",
        "verts_rgb = torch.ones_like(verts)[None]  # (1, V, 3)\n",
        "textures = TexturesVertex(verts_features=verts_rgb.to(device))\n",
        "\n",
        "# Create a Meshes object\n",
        "mesh = Meshes(\n",
        "    verts=[verts.to(device)],   \n",
        "    faces=[faces.to(device)],\n",
        "    textures=textures\n",
        ")\n",
        "\n",
        "# Render the plotly figure\n",
        "fig = plot_scene({\n",
        "    \"Human motion\": {\n",
        "        \"person\": mesh\n",
        "    }\n",
        "})\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
